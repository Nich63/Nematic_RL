{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorboard\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.model import DownSampleConv, UpSampleConv\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3, 257)\n",
      "(256, 256, 217)\n",
      "(217, 256, 256)\n",
      "(217, 2, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "D = sio.loadmat('/home/hou63/pj2/Nematic_RL/datas/D.mat')['D']\n",
    "# print keys\n",
    "print(D.shape)\n",
    "d11 = D[:,:,0,40:]\n",
    "d12 = D[:,:,1,40:]\n",
    "print(d11.shape)\n",
    "# put axis 2 to 0\n",
    "d11 = np.moveaxis(d11, 2, 0)\n",
    "d12 = np.moveaxis(d12, 2, 0)\n",
    "print(d11.shape)\n",
    "ds = np.stack((d11, d12), axis=1)\n",
    "print(ds.shape)\n",
    "ds = torch.tensor(ds, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot D\n",
    "plt.figure()\n",
    "plt.imshow(d11[:,:,0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 训练参数\u001b[39;00m\n\u001b[1;32m     11\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(\u001b[43mds\u001b[49m)  \u001b[38;5;66;03m# 将 ds 封装为 dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = DownSampleConv()\n",
    "decoder = UpSampleConv()\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "\n",
    "# 训练参数\n",
    "num_epochs = 10\n",
    "dataset = TensorDataset(ds)  # 将 ds 封装为 dataset\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m decoder\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# 设置 decoder 为训练模式\u001b[39;00m\n\u001b[1;32m     10\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader\u001b[49m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# 将数据移到设备上\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# 前向传播: encoder 和 decoder\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "save_path = '/home/hou63/pj2/Nematic_RL/log_model/encoder_checkpoint.pth'  # 模型保存路径\n",
    "best_loss = float('inf')  # 初始最优损失值设为无穷大\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()  # 设置 encoder 为训练模式\n",
    "    decoder.train()  # 设置 decoder 为训练模式\n",
    "    \n",
    "    total_loss = 0.0\n",
    "\n",
    "    for data in dataloader:\n",
    "        # 将数据移到设备上\n",
    "        x = data[0].to(device)\n",
    "        \n",
    "        # 前向传播: encoder 和 decoder\n",
    "        encoded = encoder(x)\n",
    "        reconstructed = decoder(encoded)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(reconstructed, x)  # 自监督损失：重建误差\n",
    "        \n",
    "        # 反向传播与优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # 保存模型：当当前损失小于最佳损失时，保存模型\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(encoder.state_dict(), save_path)\n",
    "        print(f'Model saved with loss {best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_562286/2469840783.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DownSampleConv(\n",
       "  (conv1): Conv2d(2, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (norm1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load encoder model\n",
    "encoder.load_state_dict(torch.load(save_path))\n",
    "encoder.eval()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
